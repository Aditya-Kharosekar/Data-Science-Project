{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TrevorE/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2010\n",
      "Mean error rate: 0.45299145299145294\n",
      "Accuracy: 0.5470085470085471\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 53 264]\n",
      " [ 54 331]]\n",
      "\n",
      "Year:  2011\n",
      "Mean error rate: 0.4485714285714286\n",
      "Accuracy: 0.5514285714285714\n",
      "Confusion matrix for XGBoost: \n",
      "[[133 193]\n",
      " [121 253]]\n",
      "\n",
      "Year:  2012\n",
      "Mean error rate: 0.4387464387464387\n",
      "Accuracy: 0.5612535612535613\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 96 221]\n",
      " [ 87 298]]\n",
      "\n",
      "Year:  2013\n",
      "Mean error rate: 0.449358059914408\n",
      "Accuracy: 0.550641940085592\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 85 249]\n",
      " [ 66 301]]\n",
      "\n",
      "Year:  2014\n",
      "Mean error rate: 0.47\n",
      "Accuracy: 0.53\n",
      "Confusion matrix for XGBoost: \n",
      "[[140 170]\n",
      " [159 231]]\n",
      "\n",
      "Year:  2015\n",
      "Mean error rate: 0.48930099857346643\n",
      "Accuracy: 0.5106990014265336\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 60 282]\n",
      " [ 61 298]]\n",
      "\n",
      "Year:  2016\n",
      "Mean error rate: 0.46494992846924177\n",
      "Accuracy: 0.5350500715307582\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 83 252]\n",
      " [ 73 291]]\n",
      "\n",
      "Year:  2017\n",
      "Mean error rate: 0.41226818830242506\n",
      "Accuracy: 0.5877318116975749\n",
      "Confusion matrix for XGBoost: \n",
      "[[105 221]\n",
      " [ 68 307]]\n",
      "\n",
      "Average accuracy:  0.546726688054\n"
     ]
    }
   ],
   "source": [
    "params = {'gamma': 10,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_depth': 6,\n",
    " 'min_child_weight': 5,\n",
    " 'n_estimators': 200,\n",
    " 'subsample': 0.5}\n",
    "year = 2010\n",
    "years = [2010+i for i in range(8)]\n",
    "baseline = [0.5588477366255145, 0.5253190613421161, 0.5329218106995884, 0.5376388317564789, 0.5300411522633744, 0.541786743515850,\n",
    "            0.5300658978583196, 0.5395061728395062]\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "features = []\n",
    "num_models = 10\n",
    "for i in range(8):\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv('Rolling Average Stats/' + str(year) +'.csv')\n",
    "\n",
    "    # Create observation and labels\n",
    "    X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher','homeLine','awayLine'], 1)\n",
    "    y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "    # Use 1st 2/3rds of season for training, test on last 1/3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    pred_avg = np.zeros(len(y_test))\n",
    "    features = []\n",
    "\n",
    "    for i in random.sample(range(1, 1000000), num_models): #[30, 595, 123, 4849, 3, 1010, 234, 8267, 3736, 99999]:\n",
    "        clfi =  XGBClassifier(**params, silent=False, seed=i)\n",
    "        clfi.fit(X_train, y_train.values.ravel())\n",
    "        clfi_pred = clfi.predict(X_test) \n",
    "        pred_avg = pred_avg + (1/num_models)*clfi_pred\n",
    "        features.append(clfi)\n",
    "\n",
    "    pred_avg = np.round(pred_avg)\n",
    "    # Report mean error rate\n",
    "    accuracy = accuracy_score(y_test, pred_avg)\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Year: ', year)\n",
    "    print(\"Mean error rate: {}\\nAccuracy: {}\".format(error_rate, accuracy))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Report confusion matrix for each classifier\n",
    "    confusion = confusion_matrix(y_test, pred_avg)\n",
    "    print(\"Confusion matrix for XGBoost: \\n{}\\n\".format(confusion))\n",
    "    confusions.append(confusion)\n",
    "    year += 1\n",
    "    \n",
    "print('Average accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2010\n",
      "Mean error rate: 0.4757834757834758\n",
      "Accuracy: 0.5242165242165242\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 80 237]\n",
      " [ 97 288]]\n",
      "\n",
      "Year:  2011\n",
      "Mean error rate: 0.4614285714285714\n",
      "Accuracy: 0.5385714285714286\n",
      "Confusion matrix for XGBoost: \n",
      "[[164 162]\n",
      " [161 213]]\n",
      "\n",
      "Year:  2012\n",
      "Mean error rate: 0.48005698005698005\n",
      "Accuracy: 0.51994301994302\n",
      "Confusion matrix for XGBoost: \n",
      "[[117 200]\n",
      " [137 248]]\n",
      "\n",
      "Year:  2013\n",
      "Mean error rate: 0.4693295292439372\n",
      "Accuracy: 0.5306704707560628\n",
      "Confusion matrix for XGBoost: \n",
      "[[125 209]\n",
      " [120 247]]\n",
      "\n",
      "Year:  2014\n",
      "Mean error rate: 0.4585714285714285\n",
      "Accuracy: 0.5414285714285715\n",
      "Confusion matrix for XGBoost: \n",
      "[[169 141]\n",
      " [180 210]]\n",
      "\n",
      "Year:  2015\n",
      "Mean error rate: 0.4821683309557775\n",
      "Accuracy: 0.5178316690442225\n",
      "Confusion matrix for XGBoost: \n",
      "[[104 238]\n",
      " [100 259]]\n",
      "\n",
      "Year:  2016\n",
      "Mean error rate: 0.49499284692417744\n",
      "Accuracy: 0.5050071530758226\n",
      "Confusion matrix for XGBoost: \n",
      "[[113 222]\n",
      " [124 240]]\n",
      "\n",
      "Year:  2017\n",
      "Mean error rate: 0.4536376604850214\n",
      "Accuracy: 0.5463623395149786\n",
      "Confusion matrix for XGBoost: \n",
      "[[130 196]\n",
      " [122 253]]\n",
      "\n",
      "Average accuracy:  0.528003897069\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'max_depth' : 100,\n",
    "    'max_features' : 44, \n",
    "    'n_estimators' : 200\n",
    "}\n",
    "\n",
    "year = 2010\n",
    "years = [2010+i for i in range(8)]\n",
    "baseline = [0.5588477366255145, 0.5253190613421161, 0.5329218106995884, 0.5376388317564789, 0.5300411522633744, 0.541786743515850,\n",
    "            0.5300658978583196, 0.5395061728395062]\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "features = []\n",
    "for i in range(8):\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv('Rolling Average Stats/' + str(year) +'.csv')\n",
    "\n",
    "    # Create observation and labels\n",
    "    X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher','homeLine','awayLine'], 1)\n",
    "    y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "    # Use 1st 2/3rds of season for training, test on last 1/3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    features = []\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    \n",
    "    # Report mean error rate\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Year: ', year)\n",
    "    print(\"Mean error rate: {}\\nAccuracy: {}\".format(error_rate, accuracy))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Report confusion matrix for each classifier\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix for XGBoost: \\n{}\\n\".format(confusion))\n",
    "    confusions.append(confusion)\n",
    "    year += 1\n",
    "    \n",
    "print('Average accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2010\n",
      "Mean error rate: 0.4658119658119658\n",
      "Accuracy: 0.5341880341880342\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 57 260]\n",
      " [ 67 318]]\n",
      "\n",
      "Year:  2011\n",
      "Mean error rate: 0.4585714285714285\n",
      "Accuracy: 0.5414285714285715\n",
      "Confusion matrix for XGBoost: \n",
      "[[140 186]\n",
      " [135 239]]\n",
      "\n",
      "Year:  2012\n",
      "Mean error rate: 0.4686609686609686\n",
      "Accuracy: 0.5313390313390314\n",
      "Confusion matrix for XGBoost: \n",
      "[[104 213]\n",
      " [116 269]]\n",
      "\n",
      "Year:  2013\n",
      "Mean error rate: 0.4664764621968617\n",
      "Accuracy: 0.5335235378031383\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 79 255]\n",
      " [ 72 295]]\n",
      "\n",
      "Year:  2014\n",
      "Mean error rate: 0.4642857142857143\n",
      "Accuracy: 0.5357142857142857\n",
      "Confusion matrix for XGBoost: \n",
      "[[149 161]\n",
      " [164 226]]\n",
      "\n",
      "Year:  2015\n",
      "Mean error rate: 0.4864479315263909\n",
      "Accuracy: 0.5135520684736091\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 65 277]\n",
      " [ 64 295]]\n",
      "\n",
      "Year:  2016\n",
      "Mean error rate: 0.46494992846924177\n",
      "Accuracy: 0.5350500715307582\n",
      "Confusion matrix for XGBoost: \n",
      "[[100 235]\n",
      " [ 90 274]]\n",
      "\n",
      "Year:  2017\n",
      "Mean error rate: 0.45078459343794575\n",
      "Accuracy: 0.5492154065620543\n",
      "Confusion matrix for XGBoost: \n",
      "[[124 202]\n",
      " [114 261]]\n",
      "\n",
      "Average accuracy:  0.53425137588\n"
     ]
    }
   ],
   "source": [
    "year = 2010\n",
    "years = [2010+i for i in range(8)]\n",
    "baseline = [0.5588477366255145, 0.5253190613421161, 0.5329218106995884, 0.5376388317564789, 0.5300411522633744, 0.541786743515850,\n",
    "            0.5300658978583196, 0.5395061728395062]\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "features = []\n",
    "for i in range(8):\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv('Rolling Average Stats/' + str(year) +'.csv')\n",
    "\n",
    "    # Create observation and labels\n",
    "    X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher','homeLine','awayLine'], 1)\n",
    "    y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "    # Use 1st 2/3rds of season for training, test on last 1/3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    features = []\n",
    "    svm = SVC(C=1)\n",
    "    svm.fit(X_train, y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    \n",
    "    # Report mean error rate\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Year: ', year)\n",
    "    print(\"Mean error rate: {}\\nAccuracy: {}\".format(error_rate, accuracy))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Report confusion matrix for each classifier\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix for XGBoost: \\n{}\\n\".format(confusion))\n",
    "    confusions.append(confusion)\n",
    "    year += 1\n",
    "    \n",
    "print('Average accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2010\n",
      "Mean error rate: 0.4757834757834758\n",
      "Accuracy: 0.5242165242165242\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 81 236]\n",
      " [ 98 287]]\n",
      "\n",
      "Year:  2011\n",
      "Mean error rate: 0.47\n",
      "Accuracy: 0.53\n",
      "Confusion matrix for XGBoost: \n",
      "[[132 194]\n",
      " [135 239]]\n",
      "\n",
      "Year:  2012\n",
      "Mean error rate: 0.45868945868945865\n",
      "Accuracy: 0.5413105413105413\n",
      "Confusion matrix for XGBoost: \n",
      "[[107 210]\n",
      " [112 273]]\n",
      "\n",
      "Year:  2013\n",
      "Mean error rate: 0.4436519258202568\n",
      "Accuracy: 0.5563480741797432\n",
      "Confusion matrix for XGBoost: \n",
      "[[127 207]\n",
      " [104 263]]\n",
      "\n",
      "Year:  2014\n",
      "Mean error rate: 0.4571428571428572\n",
      "Accuracy: 0.5428571428571428\n",
      "Confusion matrix for XGBoost: \n",
      "[[155 155]\n",
      " [165 225]]\n",
      "\n",
      "Year:  2015\n",
      "Mean error rate: 0.4864479315263909\n",
      "Accuracy: 0.5135520684736091\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 73 269]\n",
      " [ 72 287]]\n",
      "\n",
      "Year:  2016\n",
      "Mean error rate: 0.4277539341917024\n",
      "Accuracy: 0.5722460658082976\n",
      "Confusion matrix for XGBoost: \n",
      "[[132 203]\n",
      " [ 96 268]]\n",
      "\n",
      "Year:  2017\n",
      "Mean error rate: 0.47075606276747506\n",
      "Accuracy: 0.5292439372325249\n",
      "Confusion matrix for XGBoost: \n",
      "[[126 200]\n",
      " [130 245]]\n",
      "\n",
      "Average accuracy:  0.53872179426\n"
     ]
    }
   ],
   "source": [
    "year = 2010\n",
    "years = [2010+i for i in range(8)]\n",
    "baseline = [0.5588477366255145, 0.5253190613421161, 0.5329218106995884, 0.5376388317564789, 0.5300411522633744, 0.541786743515850,\n",
    "            0.5300658978583196, 0.5395061728395062]\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "features = []\n",
    "for i in range(8):\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv('Rolling Average Stats/' + str(year) +'.csv')\n",
    "\n",
    "    # Create observation and labels\n",
    "    X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher','homeLine','awayLine'], 1)\n",
    "    y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "    # Use 1st 2/3rds of season for training, test on last 1/3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    features = []\n",
    "    reg = LogisticRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    # Report mean error rate\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Year: ', year)\n",
    "    print(\"Mean error rate: {}\\nAccuracy: {}\".format(error_rate, accuracy))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Report confusion matrix for each classifier\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix for XGBoost: \\n{}\\n\".format(confusion))\n",
    "    confusions.append(confusion)\n",
    "    year += 1\n",
    "\n",
    "print('Average accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2010\n",
      "Mean error rate: 0.47720797720797725\n",
      "Accuracy: 0.5227920227920227\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 49 268]\n",
      " [ 67 318]]\n",
      "\n",
      "Year:  2011\n",
      "Mean error rate: 0.44571428571428573\n",
      "Accuracy: 0.5542857142857143\n",
      "Confusion matrix for XGBoost: \n",
      "[[110 216]\n",
      " [ 96 278]]\n",
      "\n",
      "Year:  2012\n",
      "Mean error rate: 0.4786324786324786\n",
      "Accuracy: 0.5213675213675214\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 67 250]\n",
      " [ 86 299]]\n",
      "\n",
      "Year:  2013\n",
      "Mean error rate: 0.463623395149786\n",
      "Accuracy: 0.536376604850214\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 76 258]\n",
      " [ 67 300]]\n",
      "\n",
      "Year:  2014\n",
      "Mean error rate: 0.4742857142857143\n",
      "Accuracy: 0.5257142857142857\n",
      "Confusion matrix for XGBoost: \n",
      "[[136 174]\n",
      " [158 232]]\n",
      "\n",
      "Year:  2015\n",
      "Mean error rate: 0.5064194008559202\n",
      "Accuracy: 0.49358059914407987\n",
      "Confusion matrix for XGBoost: \n",
      "[[ 60 282]\n",
      " [ 73 286]]\n",
      "\n",
      "Year:  2016\n",
      "Mean error rate: 0.45779685264663805\n",
      "Accuracy: 0.542203147353362\n",
      "Confusion matrix for XGBoost: \n",
      "[[103 232]\n",
      " [ 88 276]]\n",
      "\n",
      "Year:  2017\n",
      "Mean error rate: 0.449358059914408\n",
      "Accuracy: 0.550641940085592\n",
      "Confusion matrix for XGBoost: \n",
      "[[115 211]\n",
      " [104 271]]\n",
      "\n",
      "Average accuracy:  0.530870229449\n"
     ]
    }
   ],
   "source": [
    "year = 2010\n",
    "years = [2010+i for i in range(8)]\n",
    "baseline = [0.5588477366255145, 0.5253190613421161, 0.5329218106995884, 0.5376388317564789, 0.5300411522633744, 0.541786743515850,\n",
    "            0.5300658978583196, 0.5395061728395062]\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "features = []\n",
    "for i in range(8):\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv('Rolling Average Stats/' + str(year) +'.csv')\n",
    "\n",
    "    # Create observation and labels\n",
    "    X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher','homeLine','awayLine'], 1)\n",
    "    y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "    # Use 1st 2/3rds of season for training, test on last 1/3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    features = []\n",
    "    mlp = MLPClassifier(solver='sgd', learning_rate='adaptive', hidden_layer_sizes=(30, 20))\n",
    "    mlp.fit(X_train, y_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "    \n",
    "    # Report mean error rate\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Year: ', year)\n",
    "    print(\"Mean error rate: {}\\nAccuracy: {}\".format(error_rate, accuracy))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Report confusion matrix for each classifier\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix for XGBoost: \\n{}\\n\".format(confusion))\n",
    "    confusions.append(confusion)\n",
    "    year += 1\n",
    "    \n",
    "print('Average accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
