{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0        True\n",
       "1        True\n",
       "2        True\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6        True\n",
       "7        True\n",
       "8        True\n",
       "9        True\n",
       "10       True\n",
       "11       True\n",
       "12      False\n",
       "13      False\n",
       "14       True\n",
       "15       True\n",
       "16       True\n",
       "17       True\n",
       "18      False\n",
       "19      False\n",
       "20       True\n",
       "21      False\n",
       "22      False\n",
       "23       True\n",
       "24       True\n",
       "25      False\n",
       "26       True\n",
       "27      False\n",
       "28      False\n",
       "29       True\n",
       "        ...  \n",
       "2093     True\n",
       "2094    False\n",
       "2095     True\n",
       "2096    False\n",
       "2097    False\n",
       "2098     True\n",
       "2099    False\n",
       "2100    False\n",
       "2101     True\n",
       "2102    False\n",
       "2103     True\n",
       "2104    False\n",
       "2105     True\n",
       "2106     True\n",
       "2107     True\n",
       "2108    False\n",
       "2109    False\n",
       "2110    False\n",
       "2111     True\n",
       "2112     True\n",
       "2113    False\n",
       "2114    False\n",
       "2115     True\n",
       "2116    False\n",
       "2117     True\n",
       "2118    False\n",
       "2119     True\n",
       "2120    False\n",
       "2121     True\n",
       "2122    False\n",
       "Length: 2123, dtype: bool>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Read in dataset\n",
    "df = pd.read_csv('Rolling Average Stats/2017.csv')\n",
    "\n",
    "# Create observation and labels\n",
    "X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher'], 1)\n",
    "y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "\n",
    "# Use 1st 2/3rds of season for training, test on last 1/3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train time : 393.45840\n"
     ]
    }
   ],
   "source": [
    "# Specify XGBoost parameters\n",
    "max_depth = [1, 3, 7, 10]\n",
    "min_child_weight = [0.1,0.5, 1, 2, 5]\n",
    "gamma = [0, 1, 10, 100]\n",
    "subsample = [0.5, 1]\n",
    "learning_rate = [0.01, 0.1, 1]\n",
    "#colsample_bytree = [0.5, 1] # Didn't help\n",
    "eta = [0.01,0.3, 1] # if eta (step size) goes down, num_rounds must go up\n",
    "#num_round = # Not sure what the default value is, so not sure what to try\n",
    "\n",
    "parameters = {'max_depth':max_depth, 'gamma':gamma, 'learning_rate':eta, 'min_child_weight':min_child_weight, \n",
    "              'subsample':subsample, 'learning_rate':learning_rate}\n",
    "\n",
    "# Create classifier\n",
    "clf = GridSearchCV(XGBClassifier(), parameters)\n",
    "\n",
    "# Train classifier\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "clf_fit_time = (time.time() - start_time)\n",
    "\n",
    "# Report time of execution\n",
    "print(\"XGBoost train time : {:.5f}\".format(clf_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost predict time: 0.00365 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test classifier\n",
    "start_time = time.time()\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_pred_time = (time.time() - start_time)\n",
    "\n",
    "# Report time of execution\n",
    "print(\"XGBoost predict time: {:.5f} seconds\".format(clf_pred_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error rate for XGBoost: \n",
      "0.44650499286733236 \n",
      "Accuracy rate for XGBoost: \n",
      "0.5534950071326676\n",
      "Confusion matrix for XGBoost: \n",
      "[[125 201]\n",
      " [112 263]]\n"
     ]
    }
   ],
   "source": [
    "# Report mean error rate\n",
    "accuracy = accuracy_score(y_test, clf_pred)\n",
    "error_rate = 1 - accuracy\n",
    "print(\"Mean error rate for XGBoost: \\n{} \\nAccuracy rate for XGBoost: \\n{}\".format(error_rate, accuracy))\n",
    "\n",
    "# Report confusion matrix for each classifier\n",
    "print(\"Confusion matrix for XGBoost: \\n{}\".format(confusion_matrix(y_test, clf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(44, 44, 44, 44), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(max_iter=200, solver='adam', learning_rate='adaptive', hidden_layer_sizes=(44,44,44,44))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549215406562\n",
      "[[ 37 289]\n",
      " [ 27 348]]\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "print(accuracy)\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549215406562\n",
      "[[ 37 289]\n",
      " [ 27 348]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC(kernel='poly')\n",
    "svm.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "print(accuracy)\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
