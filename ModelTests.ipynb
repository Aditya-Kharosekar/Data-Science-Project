{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TrevorE/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Read in dataset\n",
    "df = pd.read_csv('Rolling Average Stats/2017.csv')\n",
    "\n",
    "# Create observation and labels\n",
    "X = df.drop(['date', 'home_team', 'away_team', 'home_score', 'away_score', 'home_pitcher', 'away_pitcher'], 1)\n",
    "y = df.home_score > df.away_score # 1 if home team wins, 0 otherwise\n",
    "\n",
    "# Use 1st 2/3rds of season for training, test on last 1/3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify XGBoost parameters\n",
    "max_depth = [1, 3, 7, 10]\n",
    "min_child_weight = [0.1,0.5, 1, 2, 5]\n",
    "gamma = [0, 1, 10, 100]\n",
    "subsample = [0.5, 1]\n",
    "learning_rate = [0.01, 0.1, 1]\n",
    "#colsample_bytree = [0.5, 1] # Didn't help\n",
    "eta = [0.01,0.3, 1] # if eta (step size) goes down, num_rounds must go up\n",
    "#num_round = # Not sure what the default value is, so not sure what to try\n",
    "\n",
    "parameters = {'max_depth':max_depth, 'gamma':gamma, 'learning_rate':eta, 'min_child_weight':min_child_weight, \n",
    "              'subsample':subsample, 'learning_rate':learning_rate}\n",
    "\n",
    "# Create classifier\n",
    "clf = GridSearchCV(XGBClassifier(), parameters)\n",
    "\n",
    "# Train classifier\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "clf_fit_time = (time.time() - start_time)\n",
    "\n",
    "# Report time of execution\n",
    "print(\"XGBoost train time : {:.5f}\".format(clf_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classifier\n",
    "start_time = time.time()\n",
    "clf_pred = clf.predict(X_test)\n",
    "clf_pred_time = (time.time() - start_time)\n",
    "\n",
    "# Report time of execution\n",
    "print(\"XGBoost predict time: {:.5f} seconds\".format(clf_pred_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report mean error rate\n",
    "accuracy = accuracy_score(y_test, clf_pred)\n",
    "error_rate = 1 - accuracy\n",
    "print(\"Mean error rate for XGBoost: \\n{} \\nAccuracy rate for XGBoost: \\n{}\".format(error_rate, accuracy))\n",
    "\n",
    "# Report confusion matrix for each classifier\n",
    "print(\"Confusion matrix for XGBoost: \\n{}\".format(confusion_matrix(y_test, clf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519623233909\n",
      "0.5431711146\n",
      "0.551020408163\n",
      "0.532182103611\n",
      "0.516483516484\n",
      "0.50863422292\n",
      "0.562009419152\n",
      "0.518053375196\n",
      "0.538461538462\n",
      "0.533751962323\n",
      "0.565149136578\n",
      "0.580847723705\n",
      "0.571428571429\n",
      "0.555729984301\n",
      "0.546310832025\n",
      "0.551020408163\n",
      "0.568288854003\n",
      "0.5431711146\n",
      "0.555729984301\n",
      "0.562009419152\n",
      "0.521193092622\n",
      "0.576138147567\n",
      "0.521193092622\n",
      "0.568288854003\n",
      "0.527472527473\n",
      "0.533751962323\n",
      "0.562009419152\n",
      "0.533751962323\n",
      "0.536891679749\n",
      "0.547880690738\n",
      "0.536891679749\n",
      "0.507064364207\n",
      "0.549450549451\n",
      "0.511773940345\n",
      "0.514913657771\n",
      "0.540031397174\n",
      "0.56043956044\n",
      "0.514913657771\n",
      "0.519623233909\n",
      "0.503924646782\n",
      "0.580847723705\n",
      "0.541601255887\n",
      "0.529042386185\n",
      "0.557299843014\n",
      "0.558869701727\n",
      "0.582417582418\n",
      "0.533751962323\n",
      "0.538461538462\n",
      "0.552590266876\n",
      "0.529042386185\n",
      "0.538461538462\n",
      "0.5431711146\n",
      "0.538461538462\n",
      "0.529042386185\n",
      "0.5431711146\n",
      "0.536891679749\n",
      "0.557299843014\n",
      "0.519623233909\n",
      "0.546310832025\n",
      "0.569858712716\n",
      "0.530612244898\n",
      "0.5431711146\n",
      "0.547880690738\n",
      "0.527472527473\n",
      "0.535321821036\n",
      "0.551020408163\n",
      "0.569858712716\n",
      "0.541601255887\n",
      "0.516483516484\n",
      "0.532182103611\n",
      "0.511773940345\n",
      "0.554160125589\n",
      "0.518053375196\n",
      "0.533751962323\n",
      "0.522762951334\n",
      "0.549450549451\n",
      "0.541601255887\n",
      "0.546310832025\n",
      "0.56043956044\n",
      "0.555729984301\n",
      "0.58398744113\n",
      "0.549450549451\n",
      "0.536891679749\n",
      "0.505494505495\n",
      "0.52590266876\n",
      "0.541601255887\n",
      "0.574568288854\n",
      "0.530612244898\n",
      "0.552590266876\n",
      "0.540031397174\n",
      "0.568288854003\n",
      "0.510204081633\n",
      "0.549450549451\n",
      "0.551020408163\n",
      "0.535321821036\n",
      "0.544740973312\n",
      "0.533751962323\n",
      "0.56043956044\n",
      "0.546310832025\n",
      "0.532182103611\n",
      "0.580847723705\n",
      "0.546310832025\n",
      "0.533751962323\n",
      "0.538461538462\n",
      "0.529042386185\n",
      "0.574568288854\n",
      "0.529042386185\n",
      "0.557299843014\n",
      "0.514913657771\n",
      "0.557299843014\n",
      "0.538461538462\n",
      "0.563579277865\n",
      "0.535321821036\n",
      "0.547880690738\n",
      "0.524332810047\n",
      "0.529042386185\n",
      "0.56043956044\n",
      "0.557299843014\n",
      "0.577708006279\n",
      "0.544740973312\n",
      "0.538461538462\n",
      "0.535321821036\n",
      "0.547880690738\n",
      "0.5431711146\n",
      "0.540031397174\n",
      "0.532182103611\n",
      "0.524332810047\n",
      "0.541601255887\n",
      "0.540031397174\n",
      "0.552590266876\n",
      "0.577708006279\n",
      "0.540031397174\n",
      "0.562009419152\n",
      "0.546310832025\n",
      "0.544740973312\n",
      "0.540031397174\n",
      "0.56671899529\n",
      "0.532182103611\n",
      "0.558869701727\n",
      "0.557299843014\n",
      "0.563579277865\n",
      "0.530612244898\n",
      "0.510204081633\n",
      "0.549450549451\n",
      "0.568288854003\n",
      "0.546310832025\n",
      "0.554160125589\n",
      "0.547880690738\n",
      "0.532182103611\n",
      "0.562009419152\n",
      "0.514913657771\n",
      "0.551020408163\n",
      "0.518053375196\n",
      "0.549450549451\n",
      "0.513343799058\n",
      "0.551020408163\n",
      "0.530612244898\n",
      "0.529042386185\n",
      "0.522762951334\n",
      "0.5431711146\n",
      "0.547880690738\n",
      "0.540031397174\n",
      "0.527472527473\n",
      "0.536891679749\n",
      "0.530612244898\n",
      "0.538461538462\n",
      "0.547880690738\n",
      "0.524332810047\n",
      "0.541601255887\n",
      "0.521193092622\n",
      "0.554160125589\n",
      "0.56043956044\n",
      "0.557299843014\n",
      "0.551020408163\n",
      "0.554160125589\n",
      "0.552590266876\n",
      "0.554160125589\n",
      "0.532182103611\n",
      "0.530612244898\n",
      "0.50863422292\n",
      "0.574568288854\n",
      "0.558869701727\n",
      "0.540031397174\n",
      "0.552590266876\n",
      "0.576138147567\n",
      "0.5431711146\n",
      "0.562009419152\n",
      "0.558869701727\n",
      "0.577708006279\n",
      "0.524332810047\n",
      "0.535321821036\n",
      "0.551020408163\n",
      "0.558869701727\n",
      "0.565149136578\n",
      "0.552590266876\n",
      "0.5431711146\n",
      "0.544740973312\n",
      "0.576138147567\n",
      "0.554160125589\n",
      "0.536891679749\n",
      "0.576138147567\n",
      "0.535321821036\n",
      "0.521193092622\n",
      "0.551020408163\n",
      "0.591836734694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "clf = None\n",
    "while True:\n",
    "    clf = MLPClassifier(max_iter=200, solver='sgd', learning_rate='adaptive', hidden_layer_sizes=(25,))\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predict)\n",
    "    print(accuracy)\n",
    "    if accuracy > 0.59:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "print(accuracy)\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
